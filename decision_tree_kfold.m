clear all;

% Load data
full_data = readtable('full_training.csv','ReadVariableNames', true);

% set max number of kfolds to test
max_kfold = 20;
% set number of times test is to be carried out
iterations = 10;

% initialise least loss at the maximum loss of 1
least_loss = 1;
% initialise a zero array of required length
losses = ones(iterations, (max_kfold - 2));

% create a for loop to iterate through full test
for i = 1:iterations
    % create a for loop going from 2 to tested max kfolds
    for j = 2:max_kfold
        % partition data into i number of kfolds
        c = cvpartition(full_data.class, 'KFold', j);
        
        % generate the decision tree for GDI (default)
        %ctree = fitctree(full_data, 'class', 'CVPartition', c);

        % generate the decision tree for deviance
        ctree = fitctree(full_data, 'class', 'CVPartition', c, SplitCriterion='deviance');
    
        % calculate the missclassification error rate
        loss = kfoldLoss(ctree);
        
        % append the error to vector of errors
        losses(i, j - 1) = loss;

        % display the kfold and accuracy while the script is running
        fprintf("Iteration: %d  Kfold: %d  Accuracy: %f\n", ...
            i, j, (1 - loss) * 100);
    end
end

figure;
% generate x-axis
X = 2:1:max_kfold;
% plot kfold number on the x-axis and the related losses on the y-axis
scatter(X, losses, 28, 'filled');

% generate a polynomial best fit line based on the mean of the rows of the losses array
p = polyfit(2:20, mean(losses,1),2);
% extrapolate polynomial to length of x-axis
poly_y = polyval(p,X);

hold on
% plot the average polynomial line
plot(X, poly_y)

% set labels
xlabel 'Number of kfolds';
ylabel 'Missclassification error rate';

hold off
